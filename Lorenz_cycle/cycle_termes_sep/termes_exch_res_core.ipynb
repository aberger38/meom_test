{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '/mnt/berger2/equipes/IGE/meom/workdir/berger2/fonctions/meom_fonctions/fonctions.ipynb'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.netcdf as netcdf\n",
    "import qgutils as qg\n",
    "from matplotlib import ticker, cm\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paramètres gravés dans le marbre pour le stage\n",
    "\n",
    "Delta = 10000                               #grid spacing\n",
    "f0 = 9.37456E-05                           #paramètre de Coriolis\n",
    "dh = np.array([350,750,2900])              #hauteurs des couches océaniques\n",
    "dh_b = np.array([(dh[0]+dh[1])/2,(dh[0]+dh[1])/2])\n",
    "g_prime = np.array([2.5E-02,1.25E-02])     #gravités réduites aux interfaces\n",
    "Beta = 1.75360E-11\n",
    "delta_ek = 5                               #ocean bottom Ekman thickness \n",
    "nu4 = 2E09                                 #bi-harmonic viscosity\n",
    "Ht = np.sum(dh)\n",
    "Ht_b = np.sum(dh_b)\n",
    "toc = np.array([1.31693E+01,1.81693E+01,2.41693E+01])\n",
    "bf = delta_ek*f0/(2*dh[-1])\n",
    "\n",
    "#fréquences Brunt-vaisala\n",
    "\n",
    "N_12 = g_prime[0]/((dh[0]+dh[1])/2)\n",
    "N_23 = g_prime[1]/((dh[1]+dh[2])/2)\n",
    "N2 = np.array([N_12,N_23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_abs  = '/mnt/berger2/equipes/IGE/meom/workdir/berger2/qgcm-data/double_gyre_coupled/outdata_7_dt10/'\n",
    "dir_rel  = '/mnt/berger2/equipes/IGE/meom/workdir/berger2/qgcm-data/double_gyre_coupled/outdata_6tdiff_dt10/'\n",
    "\n",
    "file0 = 'ocpo.nc'\n",
    "file1 = 'ocsst.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get fields psi\n",
    "pfile_abs = dir_abs + file0\n",
    "pfile_rel = dir_rel + file0\n",
    "\n",
    "toc_file_abs = dir_abs + file1\n",
    "toc_file_rel = dir_rel + file1\n",
    "\n",
    "\n",
    "f_abs = netcdf.netcdf_file(dir_abs + file0,'r')\n",
    "f_rel = netcdf.netcdf_file(dir_rel + file0,'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_t = f_abs.variables['time'][:].copy().size\n",
    "\n",
    "p = qg.read_qgcm(pfile_abs, 0, var='p', rescale = 1/f0, interp = True, subtract_bc = False )\n",
    "nz,ny,nx = p.shape\n",
    "\n",
    "test = si_t\n",
    "\n",
    "average = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flot moyen abs\n",
    "flot_me = np.load('/mnt/berger2/equipes/IGE/meom/workdir/berger2/git/meom_test/meom_test/Lorenz_cycle/tableaux_termes_abs/termes_flot_moyen_abs.npz')\n",
    "u_me_abs = flot_me['u_me']\n",
    "v_me_abs = flot_me['v_me']\n",
    "\n",
    "flot_me_bis = np.load('/mnt/berger2/equipes/IGE/meom/workdir/berger2/git/meom_test/meom_test/Lorenz_cycle/tableaux_termes_abs/etapes_flot_moyen_abs.npz')\n",
    "         \n",
    "p_me_abs = flot_me_bis['p_me']\n",
    "b_me_abs = flot_me_bis['b_me']\n",
    "w_me_abs = flot_me_bis['w_me']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flot moyen rel\n",
    "flot_me = np.load('/mnt/berger2/equipes/IGE/meom/workdir/berger2/git/meom_test/meom_test/Lorenz_cycle/tableaux_termes_rel/termes_flot_moyen_rel.npz')\n",
    "u_me_rel = flot_me['u_me']\n",
    "v_me_rel = flot_me['v_me']\n",
    "\n",
    "flot_me_bis = np.load('/mnt/berger2/equipes/IGE/meom/workdir/berger2/git/meom_test/meom_test/Lorenz_cycle/tableaux_termes_rel/etapes_flot_moyen_rel.npz')\n",
    "         \n",
    "p_me_rel = flot_me_bis['p_me']\n",
    "b_me_rel = flot_me_bis['b_me']\n",
    "w_me_rel = flot_me_bis['w_me']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uninterp b_me with diff\n",
    "dbdx_me_abs = np.diff(b_me_abs,1,2)/Delta\n",
    "dbdy_me_abs = np.diff(b_me_abs,1,1)/Delta\n",
    "dbdx_me_rel = np.diff(b_me_rel,1,2)/Delta\n",
    "dbdy_me_rel = np.diff(b_me_rel,1,1)/Delta\n",
    "\n",
    "\n",
    "#compute the expression sparately with padding to obtain (513,512)ish arrays\n",
    "dbdx_pad_abs = np.pad(dbdx_me_abs,((0,0),(0,0),(1,1)))\n",
    "dbdy_pad_abs = np.pad(dbdy_me_abs,((0,0),(1,1),(0,0)))\n",
    "dbdx_pad_rel = np.pad(dbdx_me_rel,((0,0),(0,0),(1,1)))\n",
    "dbdy_pad_rel = np.pad(dbdy_me_rel,((0,0),(1,1),(0,0)))\n",
    "\n",
    "#uninterp u_me and v_me with diff\n",
    "dudx_me_abs = np.diff(u_me_abs,1,2)/Delta\n",
    "dudy_me_abs = np.diff(u_me_abs,1,1)/Delta\n",
    "dvdx_me_abs = np.diff(v_me_abs,1,2)/Delta\n",
    "dvdy_me_abs = np.diff(v_me_abs,1,1)/Delta\n",
    "\n",
    "dudx_me_rel = np.diff(u_me_rel,1,2)/Delta\n",
    "dudy_me_rel = np.diff(u_me_rel,1,1)/Delta\n",
    "dvdx_me_rel = np.diff(v_me_rel,1,2)/Delta\n",
    "dvdy_me_rel = np.diff(v_me_rel,1,1)/Delta\n",
    "\n",
    "#compute the expression sparately with padding to obtain (513,512)ish arrays\n",
    "dudx_pad_abs = np.pad(dudx_me_abs,((0,0),(0,0),(1,1)))\n",
    "dudy_pad_abs = np.pad(dudy_me_abs,((0,0),(1,1),(0,0)))\n",
    "dvdx_pad_abs = np.pad(dvdx_me_abs,((0,0),(0,0),(1,1)))\n",
    "dvdy_pad_abs = np.pad(dvdy_me_abs,((0,0),(1,1),(0,0)))\n",
    "\n",
    "dudx_pad_rel = np.pad(dudx_me_rel,((0,0),(0,0),(1,1)))\n",
    "dudy_pad_rel = np.pad(dudy_me_rel,((0,0),(1,1),(0,0)))\n",
    "dvdx_pad_rel = np.pad(dvdx_me_rel,((0,0),(0,0),(1,1)))\n",
    "dvdy_pad_rel = np.pad(dvdy_me_rel,((0,0),(1,1),(0,0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 513, 512)\n"
     ]
    }
   ],
   "source": [
    "print(dvdy_pad_rel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 1s, sys: 2.88 s, total: 4min 4s\n",
      "Wall time: 8min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#physical map\n",
    "\n",
    "mpe2epe_me_abs= np.zeros((nz-1,ny,nx))\n",
    "epe2mpe_me_abs= np.zeros((nz-1,ny,nx))\n",
    "mke2eke_me_abs= np.zeros((nz,ny,nx))\n",
    "eke2mke_me_abs= np.zeros((nz,ny,nx))\n",
    "\n",
    "mpe2epe_me_rel= np.zeros((nz-1,ny,nx))\n",
    "epe2mpe_me_rel= np.zeros((nz-1,ny,nx))\n",
    "mke2eke_me_rel= np.zeros((nz,ny,nx))\n",
    "eke2mke_me_rel= np.zeros((nz,ny,nx))\n",
    "\n",
    "\n",
    "n_me=1\n",
    "\n",
    "for it in range(0,test):\n",
    "    \n",
    "    p_abs = qg.read_qgcm(pfile_abs, it, var='p', rescale = 1/f0, interp = True, subtract_bc = True)\n",
    "    p_rel = qg.read_qgcm(pfile_rel, it, var='p', rescale = 1/f0, interp = True, subtract_bc = True) \n",
    "    \n",
    "    u_abs,v_abs = qg.comp_vel(p_abs, Delta=Delta, loc='center')\n",
    "    u_rel,v_rel = qg.comp_vel(p_rel, Delta=Delta, loc='center')\n",
    "    \n",
    "    b_abs = qg.p2b(p_abs, dh, f0)\n",
    "    b_rel = qg.p2b(p_rel, dh, f0)\n",
    "  \n",
    "    u_p_abs = u_abs - u_me_abs\n",
    "    v_p_abs = v_abs - v_me_abs\n",
    "    b_p_abs = b_abs - b_me_abs\n",
    "    p_p_abs = p_abs - p_me_abs\n",
    "    \n",
    "    u_p_rel = u_rel - u_me_rel\n",
    "    v_p_rel = v_rel - v_me_rel\n",
    "    b_p_rel = b_rel - b_me_rel\n",
    "    p_p_rel = p_rel - p_me_rel\n",
    "        \n",
    "    u_p_abs_use = reduce_z_dim(u_p_abs, dh)\n",
    "    v_p_abs_use = reduce_z_dim(v_p_abs, dh)\n",
    "    u_p_rel_use = reduce_z_dim(u_p_rel, dh)\n",
    "    v_p_rel_use = reduce_z_dim(v_p_rel, dh)\n",
    "    \n",
    "    #MPE to EPE, MPE perspective\n",
    "    \n",
    "    #uninterp b with diff\n",
    "    dbdx_abs = np.diff(b_abs,1,2)/Delta\n",
    "    dbdy_abs = np.diff(b_abs,1,1)/Delta\n",
    "    dbdx_rel = np.diff(b_rel,1,2)/Delta\n",
    "    dbdy_rel = np.diff(b_rel,1,1)/Delta\n",
    "\n",
    "    #uninterp u and v with average of\n",
    "    u_unx_abs = 0.5*(u_p_abs_use[:,:,1:] + u_p_abs_use[:,:,:-1])\n",
    "    v_uny_abs = 0.5*(v_p_abs_use[:,1:,:] + v_p_abs_use[:,:-1,:])\n",
    "    u_unx_rel = 0.5*(u_p_rel_use[:,:,1:] + u_p_rel_use[:,:,:-1])\n",
    "    v_uny_rel = 0.5*(v_p_rel_use[:,1:,:] + v_p_rel_use[:,:-1,:])\n",
    "\n",
    "    #compute the expression sparately with padding to obtain (513,512)ish arrays\n",
    "    u_dbdx_abs = np.pad(u_unx_abs*dbdx_abs,((0,0),(0,0),(1,1)))\n",
    "    v_dbdy_abs = np.pad(v_uny_abs*dbdy_abs,((0,0),(1,1),(0,0)))\n",
    "    u_dbdx_rel = np.pad(u_unx_rel*dbdx_rel,((0,0),(0,0),(1,1)))\n",
    "    v_dbdy_rel = np.pad(v_uny_rel*dbdy_rel,((0,0),(1,1),(0,0)))\n",
    "\n",
    "\n",
    "    #compute the expression\n",
    "    mpe2epe_abs = (-b_me_abs/N2[:,None,None])*0.5*(u_dbdx_abs[:,:,1:] + u_dbdx_abs[:,:,:-1] + v_dbdy_abs[:,1:,:] + v_dbdy_abs[:,:-1,:])\n",
    "    mpe2epe_rel = (-b_me_rel/N2[:,None,None])*0.5*(u_dbdx_rel[:,:,1:] + u_dbdx_rel[:,:,:-1] + v_dbdy_rel[:,1:,:] + v_dbdy_rel[:,:-1,:])\n",
    "    \n",
    "    #MPE to EPE, EPE perspective\n",
    "    \n",
    "    \n",
    "    epe2mpe_abs = (0.5/N2[:,None,None])*((dbdx_pad_abs[:,:,1:] + dbdx_pad_abs[:,:,:-1])*u_p_abs_use*b_p_abs\n",
    "                + (dbdy_pad_abs[:,:-1,:]+dbdy_pad_abs[:,1:,:])*v_p_abs_use*b_p_abs)\n",
    "    \n",
    "    \n",
    "    \n",
    "    epe2mpe_rel = (0.5/N2[:,None,None])*((dbdx_pad_rel[:,:,1:] + dbdx_pad_rel[:,:,:-1])*u_p_rel_use*b_p_rel\n",
    "                + (dbdy_pad_rel[:,:-1,:]+dbdy_pad_rel[:,1:,:])*v_p_rel_use*b_p_rel)\n",
    "    \n",
    "    #MKE to EKE, EKE perspective\n",
    "    #uninterp u_p and v_p products with diff\n",
    "    du2_dx_abs = np.diff(u_p_abs**2, 1,2)/Delta\n",
    "    duv_dy_abs = np.diff(u_p_abs*v_p_abs,1,1)/Delta\n",
    "    duv_dx_abs = np.diff(u_p_abs*v_p_abs,1,2)/Delta\n",
    "    dv2_dy_abs = np.diff(v_p_abs**2, 1,1)/Delta\n",
    "    \n",
    "    du2_dx_rel = np.diff(u_p_rel**2, 1,2)/Delta\n",
    "    duv_dy_rel = np.diff(u_p_rel*v_p_rel,1,1)/Delta\n",
    "    duv_dx_rel = np.diff(u_p_rel*v_p_rel,1,2)/Delta\n",
    "    dv2_dy_rel = np.diff(v_p_rel**2, 1,1)/Delta\n",
    "\n",
    "    #compute the expression sparately with padding to obtain (513,512)ish arrays\n",
    "    du2_dx_pad_abs = np.pad(du2_dx_abs,((0,0),(0,0),(1,1)))\n",
    "    duv_dy_pad_abs = np.pad(duv_dy_abs,((0,0),(1,1),(0,0)))\n",
    "    duv_dx_pad_abs = np.pad(duv_dx_abs,((0,0),(0,0),(1,1)))\n",
    "    dv2_dy_pad_abs = np.pad(dv2_dy_abs,((0,0),(1,1),(0,0)))\n",
    "    \n",
    "    du2_dx_pad_rel = np.pad(du2_dx_rel,((0,0),(0,0),(1,1)))\n",
    "    duv_dy_pad_rel = np.pad(duv_dy_rel,((0,0),(1,1),(0,0)))\n",
    "    duv_dx_pad_rel = np.pad(duv_dx_rel,((0,0),(0,0),(1,1)))\n",
    "    dv2_dy_pad_rel = np.pad(dv2_dy_rel,((0,0),(1,1),(0,0)))\n",
    "\n",
    "    eke2mke_abs = 0.5*((du2_dx_pad_abs[:,:,1:]+du2_dx_pad_abs[:,:,:-1])*u_me_abs \n",
    "              +(duv_dy_pad_abs[:,1:,:]+duv_dy_pad_abs[:,:-1,:])*u_me_abs\n",
    "              +(duv_dx_pad_abs[:,:,1:]+duv_dx_pad_abs[:,:,:-1])*v_me_abs\n",
    "              +(dv2_dy_pad_abs[:,1:,:]+dv2_dy_pad_abs[:,:-1,:])*v_me_abs)\n",
    "    \n",
    "    eke2mke_rel = 0.5*((du2_dx_pad_rel[:,:,1:]+du2_dx_pad_rel[:,:,:-1])*u_me_rel \n",
    "          +(duv_dy_pad_rel[:,1:,:]+duv_dy_pad_rel[:,:-1,:])*u_me_rel\n",
    "          +(duv_dx_pad_rel[:,:,1:]+duv_dx_pad_rel[:,:,:-1])*v_me_rel\n",
    "          +(dv2_dy_pad_rel[:,1:,:]+dv2_dy_pad_rel[:,:-1,:])*v_me_rel)\n",
    "    \n",
    "    #MKE to EKE, MKE perspective (à checker la perspective)\n",
    "    mke2eke_abs = 0.5*((dudx_pad_abs[:,:,1:]+dudx_pad_abs[:,:,:-1])*u_p_abs**2 \n",
    "          +(dudy_pad_abs[:,1:,:]+dudy_pad_abs[:,:-1,:])*u_p_abs*v_p_abs\n",
    "          +(dvdx_pad_abs[:,:,1:]+dvdx_pad_abs[:,:,:-1])*u_p_abs*v_p_abs\n",
    "          +(dvdy_pad_abs[:,1:,:]+dvdy_pad_abs[:,:-1,:])*v_p_abs**2)\n",
    "    \n",
    "    mke2eke_rel = 0.5*((dudx_pad_rel[:,:,1:]+dudx_pad_rel[:,:,:-1])*u_p_rel**2 \n",
    "          +(dudy_pad_rel[:,1:,:]+dudy_pad_rel[:,:-1,:])*u_p_rel*v_p_rel\n",
    "          +(dvdx_pad_rel[:,:,1:]+dvdx_pad_rel[:,:,:-1])*u_p_rel*v_p_rel\n",
    "          +(dvdy_pad_rel[:,1:,:]+dvdy_pad_rel[:,:-1,:])*v_p_rel**2)\n",
    "   \n",
    "    \n",
    "    mpe2epe_me_abs += (mpe2epe_abs - mpe2epe_me_abs)/n_me \n",
    "    epe2mpe_me_abs += (epe2mpe_abs - epe2mpe_me_abs)/n_me \n",
    "    mke2eke_me_abs += (mke2eke_abs - mke2eke_me_abs)/n_me \n",
    "    eke2mke_me_abs += (eke2mke_abs - eke2mke_me_abs)/n_me\n",
    "    \n",
    "    mpe2epe_me_rel += (mpe2epe_rel - mpe2epe_me_rel)/n_me \n",
    "    epe2mpe_me_rel += (epe2mpe_rel - epe2mpe_me_rel)/n_me \n",
    "    mke2eke_me_rel += (mke2eke_rel - mke2eke_me_rel)/n_me \n",
    "    eke2mke_me_rel += (eke2mke_rel - eke2mke_me_rel)/n_me\n",
    "    \n",
    "    n_me += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_b_me_abs= np.zeros((nl-1,N,naux))\n",
    "p_w_me_abs= np.zeros((nl,N,naux))\n",
    "\n",
    "w_b_me_rel= np.zeros((nl-1,N,naux))\n",
    "p_w_me_rel= np.zeros((nl,N,naux))\n",
    "\n",
    "\n",
    "n_me=1\n",
    "\n",
    "for it in range(0,test):\n",
    "    \n",
    "    p_abs = qg.read_qgcm(pfile_abs, it, var='p', rescale = 1/f0, interp = True, subtract_bc = True)\n",
    "    p_rel = qg.read_qgcm(pfile_rel, it, var='p', rescale = 1/f0, interp = True, subtract_bc = True) \n",
    "    \n",
    "    loc_forcing_z_abs = qg.read_qgcm(toc_file_abs, it, 'wekt', rescale=f0/dh[0], interp=False)\n",
    "    loc_forcing_z_rel = qg.read_qgcm(toc_file_rel, it, 'wekt', rescale=f0/dh[0], interp=False)\n",
    "    \n",
    "    loc_forcing_b_abs = qg.read_qgcm(pfile_abs, it, var='entoc', interp = True)\n",
    "    loc_forcing_b_rel = qg.read_qgcm(pfile_rel, it, var='entoc', interp = True)\n",
    "\n",
    "    w_abs = qg.get_w(p_abs,dh, N2,f0, Delta, bf,loc_forcing_z_abs, loc_forcing_b_abs, nu=0, nu4=nu4)\n",
    "    w_rel = qg.get_w(p_rel,dh, N2,f0, Delta, bf,loc_forcing_z_rel, loc_forcing_b_rel, nu=0, nu4=nu4)\n",
    "    \n",
    "    b_abs = qg.p2b(p_abs, dh, f0)\n",
    "    b_rel = qg.p2b(p_rel, dh, f0)\n",
    "  \n",
    "    w_p_abs = w_abs - w_me_abs\n",
    "    b_p_abs = b_abs - b_me_abs\n",
    "    p_p_abs = p_abs - p_me_abs\n",
    "    \n",
    "    w_p_rel = w_rel - w_me_rel\n",
    "    b_p_rel = b_rel - b_me_rel\n",
    "    p_p_rel = p_rel - p_me_rel\n",
    "    \n",
    "    w_p_abs_use = np.concatenate((zero,w_p_abs,zero), axis=0)\n",
    "    w_p_rel_use = np.concatenate((zero,w_p_rel,zero), axis=0)\n",
    "        \n",
    "    w_b_p_abs = w_p_abs*b_p_abs\n",
    "    p_w_p_abs = p_p_abs*div_z(w_p_abs_use,dh,f0)\n",
    "    w_b_p_rel = w_p_rel*b_p_rel\n",
    "    p_w_p_rel = p_p_rel*div_z(w_p_rel_use,dh,f0)\n",
    "    \n",
    "    \n",
    "    w_b_me_abs += (w_b_p_abs - w_b_me_abs)/n_me\n",
    "    p_w_me_abs += (p_w_p_abs - p_w_me_abs)/n_me\n",
    "    w_b_me_rel += (w_b_p_rel - w_b_me_rel)/n_me\n",
    "    p_w_me_rel += (p_w_p_rel - p_w_me_rel)/n_me\n",
    "    \n",
    "    n_me += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('/mnt/berger2/equipes/IGE/meom/workdir/berger2/git/meom_test//meom_test/Lorenz_cycle/cycle_termes_sep/tableaux_termes_exch/termes_abs.npz',\n",
    "    mpe2epe_me_abs = mpe2epe_me_abs,\n",
    "    epe2mpe_me_abs = epe2mpe_me_abs,\n",
    "    mke2eke_me_abs = mke2eke_me_abs, \n",
    "    eke2mke_me_abs = eke2mke_me_abs)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('/mnt/berger2/equipes/IGE/meom/workdir/berger2/git/meom_test//meom_test/Lorenz_cycle/cycle_termes_sep/tableaux_termes_exch/termes_rel.npz',\n",
    "    mpe2epe_me_rel = mpe2epe_me_rel,\n",
    "    epe2mpe_me_rel = epe2mpe_me_rel, \n",
    "    mke2eke_me_rel = mke2eke_me_rel,\n",
    "    eke2mke_me_rel = eke2mke_me_rel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
